# Private post-GAN Boosting

## American Census Data from 1940

This folder contains all data and code to replicate the findings and figures presented in Part 4.2 of Private post-GAN Boosting

## Contents

- figures: 		.png files of figures presented in paper
- gan-input:  .csv files for the GAN input
- models:     folder to store the intermediate weights of GAN training
- raw-data: 	original raw data sets (or instructions on how/where to get them)
- scripts: 		R and python code to replicate the analysis
- synthetic-output: folder to store the synthetic data generated by the four approaches in the paper
- census-1940.Rproj: Rproject for the toy-example

## How to get the raw data
- Go to [https://usa.ipums.org/usa/index.shtml](https://usa.ipums.org/usa/index.shtml).
- Click `Get Data` and select the 1940 1% sample.
- Select either all variables or only the ones used in the paper. (See code for variable names.)
- Place the resulting files in raw-data.
- Exchange the name of the .xml file in `01-data-preprocessing.R` to the name that was generated for your extract.

## Hyperparameters

### GAN Training
- Number of hidden layers: 2
	- Units per layer: (256 - 128)
- minibatch size: 100
- Discriminator learning rate
	- dp Discriminator: 0.01
		- l2_norm_clip: 1
		- noise_multiplier: 1.55
	- non-dp Discriminator: 0.001
- Generator learning rate: 0.001
- epochs: 20
- Dimension of Z: 128
- temperature for gumbel-softmax trick: 0.00001


### post-GAN Boosting
- number of models (Generators and Discriminators): 150
- save models after every 5th update steps
- number of samples per model: 5,000
- number of steps T: 400
- epsilon for post-GAN-Boosting (MW_epsilon): 0.201

